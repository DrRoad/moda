{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the MODA framework to analyze the SF 311 data\n",
    "\n",
    "Source of data: https://data.sfgov.org/City-Infrastructure/311-Cases/vw6y-z8j6/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "## The time window to bucket samples\n",
    "TIME_RANGE = '4H'\n",
    "\n",
    "## File path (original data is ~1GB, this is a reduced version with only categories and dates)\n",
    "#DATAPATH = \"SF-311-categories-2018.csv\"\n",
    "DATAPATH = \"SF311_simplified.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Opened</th>\n",
       "      <th>Category</th>\n",
       "      <th>Request Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>07/02/2008 03:16:55 PM</td>\n",
       "      <td>Tree Maintenance</td>\n",
       "      <td>Lifted_sidewalk_tree_roots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>07/02/2008 04:47:08 PM</td>\n",
       "      <td>Tree Maintenance</td>\n",
       "      <td>Hanging_limb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>07/02/2008 05:54:07 PM</td>\n",
       "      <td>Tree Maintenance</td>\n",
       "      <td>Blocking_street_lights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>07/03/2008 12:38:04 PM</td>\n",
       "      <td>Tree Maintenance</td>\n",
       "      <td>Sprinkler_system_issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>07/03/2008 12:44:26 PM</td>\n",
       "      <td>Street and Sidewalk Cleaning</td>\n",
       "      <td>Other Loose Garbage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>07/03/2008 01:24:07 PM</td>\n",
       "      <td>Tree Maintenance</td>\n",
       "      <td>Lifted_sidewalk_tree_roots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>07/07/2008 03:14:07 PM</td>\n",
       "      <td>Tree Maintenance</td>\n",
       "      <td>Near_communication_line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>07/08/2008 06:25:18 PM</td>\n",
       "      <td>Tree Maintenance</td>\n",
       "      <td>About_to_fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>07/09/2008 02:57:52 PM</td>\n",
       "      <td>Tree Maintenance</td>\n",
       "      <td>Near_communication_line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>07/09/2008 04:57:24 PM</td>\n",
       "      <td>Tree Maintenance</td>\n",
       "      <td>Near_communication_line</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  Opened                      Category  \\\n",
       "0           0  07/02/2008 03:16:55 PM              Tree Maintenance   \n",
       "1           1  07/02/2008 04:47:08 PM              Tree Maintenance   \n",
       "2           2  07/02/2008 05:54:07 PM              Tree Maintenance   \n",
       "3           3  07/03/2008 12:38:04 PM              Tree Maintenance   \n",
       "4           4  07/03/2008 12:44:26 PM  Street and Sidewalk Cleaning   \n",
       "5           5  07/03/2008 01:24:07 PM              Tree Maintenance   \n",
       "6           6  07/07/2008 03:14:07 PM              Tree Maintenance   \n",
       "7           7  07/08/2008 06:25:18 PM              Tree Maintenance   \n",
       "8           8  07/09/2008 02:57:52 PM              Tree Maintenance   \n",
       "9           9  07/09/2008 04:57:24 PM              Tree Maintenance   \n",
       "\n",
       "              Request Details  \n",
       "0  Lifted_sidewalk_tree_roots  \n",
       "1                Hanging_limb  \n",
       "2      Blocking_street_lights  \n",
       "3     Sprinkler_system_issues  \n",
       "4         Other Loose Garbage  \n",
       "5  Lifted_sidewalk_tree_roots  \n",
       "6     Near_communication_line  \n",
       "7               About_to_fall  \n",
       "8     Near_communication_line  \n",
       "9     Near_communication_line  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Raw data sample:\n",
    "raw = pd.read_csv(DATAPATH,nrows=100)\n",
    "raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moda.dataprep.raw_to_ts import raw_to_ts\n",
    "from moda.dataprep.ts_to_range import ts_to_range\n",
    "\n",
    "def prep_data(datapath, time_range='24H', nrows=None, min_date=None, max_date=None, save_files=False,file_prefix = \"\", usecols=None):\n",
    "    \"\"\"\n",
    "    Takes a raw data with timestamps (date column), categories (category column) and additional columns,\n",
    "    and turns it into a ranged time-series: Group the original raw data by time interval (time_range) and category.\n",
    "    Result is the number of samples per category in each time range.\n",
    "    :param datapath: the path to the csv file\n",
    "    :param time_range: the time_range according to which the data is grouped by\n",
    "    :param nrows: limits the number of rows read from the csv\n",
    "    :param min_date: filters out ranges prior to min_date\n",
    "    :param max_date: filters out ranges after max_date\n",
    "    :param save_files: Whether to save intermediate csvs\n",
    "    :returns a pd.DataFrame with one value per time_range and category.\n",
    "    This value is the number of samples within this range for a specific category\n",
    "    \"\"\"\n",
    "\n",
    "    if nrows is None:\n",
    "        raw = pd.read_csv(datapath, usecols=usecols)\n",
    "    else:\n",
    "        raw = pd.read_csv(datapath, usecols=usecols, nrows=nrows)\n",
    "\n",
    "    raw = raw.rename(columns={'Opened': 'date', 'Category': 'category'})\n",
    "\n",
    "    # Create a time series dataframe\n",
    "    ts = raw_to_ts(raw, min_date=min_date, max_date=max_date)\n",
    "\n",
    "    # Divide time series to ranges and categories\n",
    "    ranged_ts = ts_to_range(ts, time_range=time_range)\n",
    "\n",
    "    if save_files:\n",
    "        if nrows is None:\n",
    "            ts.to_csv(\"{}_ts.csv\".format(file_prefix))\n",
    "            ranged_ts.to_csv(\"{0}_ranged_ts_{1}.csv\".format(file_prefix,time_range))\n",
    "        else:\n",
    "            ts.to_csv(\"{0}_ts_{1}_rows.csv\".format(file_postfix,nrows))\n",
    "            ranged_ts.to_csv(\"{0}_ranged_ts_{1}_{2}_rows.csv\".format(file_prefix,time_range,nrows))\n",
    "    return ranged_ts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\moda\\dataprep\\ts_to_range.py:17: FutureWarning: pd.TimeGrouper is deprecated and will be removed; Please use pd.Grouper(freq=...)\n",
      "  range_grp = ts.groupby([pd.TimeGrouper(time_range), 'category']).agg('count')\n"
     ]
    }
   ],
   "source": [
    "# This might take some time to load\n",
    "ranged_ts_24H_2018 = prep_data(DATAPATH,time_range='24H',min_date=\"01-01-2018\",save_files = True,file_prefix = \"SF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\moda\\dataprep\\ts_to_range.py:17: FutureWarning: pd.TimeGrouper is deprecated and will be removed; Please use pd.Grouper(freq=...)\n",
      "  range_grp = ts.groupby([pd.TimeGrouper(time_range), 'category']).agg('count')\n"
     ]
    }
   ],
   "source": [
    "# This might take some time to load\n",
    "ranged_ts_4H_2016_2018 = prep_data(DATAPATH,time_range='4H',min_date=\"01-01-2016\",save_files = True,file_prefix = \"SF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a file with the number of events per category per time, we can start modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, in order to be able to estimate our models, we use [TagAnomaly](https://github.com/Microsoft/TagAnomaly) to tag the points we think are showing trends in the data. Taganomaly can be found here: https://github.com/Microsoft/TagAnomaly\n",
    "Second, we join the tagged dataset with the time series dataset. Each sample which isn't included in the tagged dataset is assumed to be non-trending (or normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-17</td>\n",
       "      <td>Blocked Street or SideWalk</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>Blocked Street or SideWalk</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-19</td>\n",
       "      <td>Blocked Street or SideWalk</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>Blocked Street or SideWalk</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-17</td>\n",
       "      <td>Blocked Street or SideWalk</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                    category  value\n",
       "0 2018-04-17  Blocked Street or SideWalk     36\n",
       "1 2018-04-18  Blocked Street or SideWalk     40\n",
       "2 2018-04-19  Blocked Street or SideWalk     31\n",
       "3 2018-04-20  Blocked Street or SideWalk     38\n",
       "4 2018-04-17  Blocked Street or SideWalk     36"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels24H = pd.read_csv('SF_24H_anomalies_only.csv',usecols=['date','category','value'])\n",
    "labels24H.date = pd.to_datetime(labels24H.date)\n",
    "labels24H.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-30 08:00:00</td>\n",
       "      <td>Abandoned Vehicle</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-30 09:00:00</td>\n",
       "      <td>Abandoned Vehicle</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-01 17:00:00</td>\n",
       "      <td>Abandoned Vehicle</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-05 08:00:00</td>\n",
       "      <td>Abandoned Vehicle</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-12 15:00:00</td>\n",
       "      <td>Abandoned Vehicle</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date           category  value\n",
       "0 2018-01-30 08:00:00  Abandoned Vehicle     16\n",
       "1 2018-01-30 09:00:00  Abandoned Vehicle     21\n",
       "2 2018-02-01 17:00:00  Abandoned Vehicle     18\n",
       "3 2018-02-05 08:00:00  Abandoned Vehicle     18\n",
       "4 2018-02-12 15:00:00  Abandoned Vehicle     16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels1H = pd.read_csv('SF_1H_anomalies_only.csv',usecols=['date','category','value'])\n",
    "labels1H.date = pd.to_datetime(labels1H.date)\n",
    "labels1H.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranged_ts_24H_2018.reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranged_ts_1H_2018.reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df24H = pd.merge(ranged_ts_24H_2018.reset_index(),labels24H,how='left',on=['date','category'])\n",
    "df24H['label'] = np.where(np.isnan(df24H['value_y']),0,1)\n",
    "df24H = df24H.drop(columns = 'value_y').rename(columns = {'value_x':'value'})\n",
    "df24H.to_csv(\"SF24H_labeled.csv\")\n",
    "\n",
    "df1H = pd.merge(ranged_ts_1H_2018.reset_index(),labels1H,how='left',on=['date','category'])\n",
    "df1H['label'] = np.where(np.isnan(df1H['value_y']),0,1)\n",
    "df1H = df1H.drop(columns = 'value_y').rename(columns = {'value_x':'value'})\n",
    "df1H.to_csv(\"SF24H_labeled.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df24H.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df24H[df24H.label > 0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moda.evaluators.eval import get_evaluation_metrics, get_final_metrics, eval_models\n",
    "from moda.models.azure_anomaly_detection.azure_ad import AzureAnomalyTrendinessDetector\n",
    "from moda.models.data_reader import read_data\n",
    "from moda.models.ma_seasonal.ma_seasonal_model import MovingAverageSeasonalTrendinessDetector\n",
    "from moda.models.stl.stl_model import STLTrendinessDetector\n",
    "from moda.models.twitter.anomaly_detect_multicategory import TwitterAnomalyTrendinessDetector\n",
    "\n",
    "\n",
    "def run_model(datapath, freq, min_date='01-01-2018', plot=True, model_name='stl', min_value=10):\n",
    "    print(\"Loading file {0}, with frequency {1}. Model name = {2}\".format(datapath, freq, model_name))\n",
    "    dataset = read_data(datapath, min_date=min_date)\n",
    "    dataset = dataset.rename(columns={'is_anomaly': 'label'})\n",
    "\n",
    "    if len(dataset.index.levels) > 1:\n",
    "        categories = dataset.index.levels[1]\n",
    "        print(\"categories found = {}\".format(categories))\n",
    "\n",
    "    if model_name == 'twitter':\n",
    "        model = TwitterAnomalyTrendinessDetector(is_multicategory=True, freq=freq, min_value=min_value, threshold=None,\n",
    "                                                 max_anoms=0.49, seasonality_freq=7)\n",
    "\n",
    "    if model_name == 'ma_seasonal':\n",
    "        model = MovingAverageSeasonalTrendinessDetector(is_multicategory=True, freq=freq, min_value=min_value,\n",
    "                                                        anomaly_type='or',\n",
    "                                                        num_of_std=3)\n",
    "\n",
    "    if model_name == 'stl':\n",
    "        model = STLTrendinessDetector(is_multicategory=True, freq=freq, min_value=min_value,\n",
    "                                      anomaly_type='or',\n",
    "                                      num_of_std=2.5, lo_delta=0)\n",
    "\n",
    "    if model_name == 'azure':\n",
    "        dirname = os.path.dirname(__file__)\n",
    "        filename = os.path.join(dirname, 'config/config.json')\n",
    "        subscription_key = get_azure_subscription_key(filename)\n",
    "        model = AzureAnomalyTrendinessDetector(is_multicategory=True, freq=freq, min_value=min_value,\n",
    "                                               subscription_key=subscription_key)\n",
    "\n",
    "    prediction = model.predict(dataset, verbose=True)\n",
    "    raw_metrics = get_evaluation_metrics(dataset[['value']], prediction[['prediction']], dataset[['label']],\n",
    "                                         window_size_for_metrics=5)\n",
    "    metrics = get_final_metrics(raw_metrics)\n",
    "    print(metrics)\n",
    "\n",
    "    ## Plot each category\n",
    "    if plot:\n",
    "        _, file = os.path.split(datapath)\n",
    "        print(\"Plotting...\")\n",
    "        model.plot(labels=dataset['label'], postfix=file)\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = run_model(\"SF24H_labeled.csv\",freq='24H',model_name='stl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
